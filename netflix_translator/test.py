
# from transformers import MBartForConditionalGeneration, MBart50TokenizerFast
# import torch

# # æª¢æŸ¥ GPU æ˜¯å¦å¯ç”¨
# device = "cpu"

# # ä½¿ç”¨ Facebook æ¨¡å‹
# MODEL_NAME = "facebook/mbart-large-50-many-to-many-mmt"
# tokenizer = MBart50TokenizerFast.from_pretrained(MODEL_NAME)
# model = MBartForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)

# # è¨­å®šèªè¨€ä»£ç¢¼ç‚ºç¹é«”ä¸­æ–‡
# target_lang = "zh_CN"

# text = "i kid you not"
# inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True).to(device)
# # é€²è¡Œç¿»è­¯
# with torch.no_grad():
#     translated = model.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id[target_lang])

# translation = tokenizer.decode(translated[0], skip_special_tokens=True)

# print("ç¿»è­¯çµæœ:", translation)

import websocket
import json

# ğŸ‘‰ é€™è£¡æ›æˆä½ è‡ªå·±çš„ JWT Access Token
JWT_TOKEN = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoiYWNjZXNzIiwiZXhwIjoxNzQ0MDg1NDU5LCJpYXQiOjE3NDQwODUxNTksImp0aSI6IjQwNDRhMDAxYzA2NTRjMmFiZjJlM2ZhZDVlM2Y2YTk2IiwidXNlcl9pZCI6MX0.Z8xQoO2NysQLPC40GCPcZOr-Z_9Vr7tQwuOEyPk3GxY"

# ğŸ‘‰ WebSocket é€£ç·š URLï¼ˆå¸¶ä¸Š tokenï¼‰
WS_URL = f"ws://localhost:8000/ws/translate/?token={JWT_TOKEN}"

def on_open(ws):
    print("ğŸ”— å·²é€£ç·šæˆåŠŸï¼Œé€å‡ºå­—å¹•...")
    test_text = "Hello, how are you today?"
    payload = json.dumps({"text": test_text})
    ws.send(payload)

def on_message(ws, message):
    print("ğŸŒ æ”¶åˆ°ç¿»è­¯å›æ‡‰ï¼š")
    print(json.loads(message))
    ws.close()

def on_error(ws, error):
    print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {error}")

def on_close(ws, close_status_code, close_msg):
    print("ğŸ”Œ é€£ç·šå·²é—œé–‰")

if __name__ == "__main__":
    websocket.enableTrace(True)  # ğŸ‘‰ debug logï¼ˆå¯ç§»é™¤ï¼‰
    ws = websocket.WebSocketApp(
        WS_URL,
        on_open=on_open,
        on_message=on_message,
        on_error=on_error,
        on_close=on_close
    )
    ws.run_forever()